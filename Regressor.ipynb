{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3e5fcc2-1620-4f44-b7ca-11d821c9610c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Œ Table 1: Model Performance (Before Tuning)\n",
      "\n",
      "                    Model  R2 Score         MAE          MSE         RMSE\n",
      "        Linear Regression  0.783593 4181.194474 3.359692e+07  5796.284659\n",
      "         Ridge Regression  0.783283 4193.585298 3.364504e+07  5800.434216\n",
      "         Lasso Regression  0.783538 4182.426034 3.360551e+07  5797.025751\n",
      "            Random Forest  0.863743 2584.099449 2.115370e+07  4599.315301\n",
      "        Gradient Boosting  0.879257 2443.483262 1.874518e+07  4329.570011\n",
      "Support Vector Regression -0.072423 8596.648704 1.664923e+08 12903.187975\n",
      "\n",
      "ðŸ“Œ Table 2: Model Performance (After GridSearchCV Tuning)\n",
      "\n",
      "                    Model  R2 Score         MAE          MSE         RMSE                                Best Params\n",
      "        Linear Regression  0.783593 4181.194474 3.359692e+07  5796.284659                                        N/A\n",
      "         Ridge Regression  0.783283 4193.585298 3.364504e+07  5800.434216                               {'alpha': 1}\n",
      "         Lasso Regression  0.783061 4192.722468 3.367951e+07  5803.405196                              {'alpha': 10}\n",
      "            Random Forest  0.867498 2508.330659 2.057079e+07  4535.502901     {'max_depth': 10, 'n_estimators': 200}\n",
      "        Gradient Boosting  0.879117 2464.898853 1.876695e+07  4332.083812 {'learning_rate': 0.1, 'n_estimators': 50}\n",
      "Support Vector Regression -0.062639 8190.242912 1.649734e+08 12844.197431                  {'C': 10, 'epsilon': 0.5}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"insurance-2.csv\")  # Change filename if needed\n",
    "\n",
    "# Assume 'charges' is the target variable\n",
    "X = df.drop(columns=[\"charges\"])  \n",
    "y = df[\"charges\"]  \n",
    "\n",
    "# Convert categorical features into numerical using One-Hot Encoding\n",
    "X = pd.get_dummies(X, drop_first=True)  # âœ… FIX for categorical data\n",
    "\n",
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Ridge Regression\": Ridge(),\n",
    "    \"Lasso Regression\": Lasso(),\n",
    "    \"Random Forest\": RandomForestRegressor(),\n",
    "    \"Gradient Boosting\": GradientBoostingRegressor(),\n",
    "    \"Support Vector Regression\": SVR()\n",
    "}\n",
    "\n",
    "# ðŸ“Œ **Table 1: Model Performance Before Tuning**\n",
    "results = []\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    \n",
    "    results.append([name, r2, mae, mse, rmse])\n",
    "\n",
    "table1 = pd.DataFrame(results, columns=[\"Model\", \"R2 Score\", \"MAE\", \"MSE\", \"RMSE\"])\n",
    "\n",
    "# âœ… Print Table 1 in a structured way\n",
    "print(\"\\nðŸ“Œ Table 1: Model Performance (Before Tuning)\\n\")\n",
    "print(table1.to_string(index=False))\n",
    "\n",
    "# ðŸ“Œ **Table 2: Model Performance After GridSearchCV & K-Fold CV**\n",
    "param_grid = {\n",
    "    \"Ridge Regression\": {\"alpha\": [0.1, 1, 10]},\n",
    "    \"Lasso Regression\": {\"alpha\": [0.1, 1, 10]},\n",
    "    \"Random Forest\": {\"n_estimators\": [100, 200], \"max_depth\": [10, 20]},\n",
    "    \"Gradient Boosting\": {\"n_estimators\": [50, 100], \"learning_rate\": [0.01, 0.1]},\n",
    "    \"Support Vector Regression\": {\"C\": [1, 10], \"epsilon\": [0.1, 0.5]}\n",
    "}\n",
    "\n",
    "results_tuned = []\n",
    "for name, model in models.items():\n",
    "    if name in param_grid:\n",
    "        grid = GridSearchCV(model, param_grid[name], cv=5, scoring=\"r2\", verbose=0)\n",
    "        grid.fit(X_train, y_train)\n",
    "        best_model = grid.best_estimator_\n",
    "        best_params = grid.best_params_\n",
    "    else:\n",
    "        best_model = model.fit(X_train, y_train)\n",
    "        best_params = \"N/A\"\n",
    "\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    \n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    \n",
    "    results_tuned.append([name, r2, mae, mse, rmse, best_params])\n",
    "\n",
    "table2 = pd.DataFrame(results_tuned, columns=[\"Model\", \"R2 Score\", \"MAE\", \"MSE\", \"RMSE\", \"Best Params\"])\n",
    "\n",
    "# âœ… Format 'Best Params' for readability\n",
    "table2[\"Best Params\"] = table2[\"Best Params\"].astype(str)\n",
    "\n",
    "# âœ… Print Table 2 in a structured way\n",
    "print(\"\\nðŸ“Œ Table 2: Model Performance (After GridSearchCV Tuning)\\n\")\n",
    "print(table2.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4d503a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30b640a8-2497-4619-a8dc-99f438a6b4b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model saved as model.pkl\n"
     ]
    }
   ],
   "source": [
    "import pickle  \n",
    "from sklearn.ensemble import GradientBoostingRegressor  \n",
    "\n",
    "# Train the best model with optimal parameters\n",
    "best_model = GradientBoostingRegressor(n_estimators=50, learning_rate=0.1)  \n",
    "best_model.fit(X_train, y_train)  \n",
    "\n",
    "# Save the trained model\n",
    "with open(\"model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(best_model, f)\n",
    "\n",
    "print(\"âœ… Model saved as model.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f14f7c-1fbf-4fe2-8aae-579a1c371aa8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
